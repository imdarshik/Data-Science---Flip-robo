{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **WEB SCRAPING ASSIGNMENT 2 - Selenium**\n",
    "Submitted by Darshik A S\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load chrome webdriver\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) To scrape data for “Data Analyst” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_10_naukri_jobs(job=None,loc=None):\n",
    "    \n",
    "    ### Get naukri webpage\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button[@class='btn']\")\n",
    "    \n",
    "    ### Enter the required desgination/location and click search \n",
    "    if job != None:\n",
    "        search_job.send_keys(job)\n",
    "    if loc != None:\n",
    "        search_location.send_keys(loc)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Find tags having the job details\n",
    "    titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    \n",
    "    ### scrape the data for the first 10 jobs results\n",
    "    title = []\n",
    "    company = []\n",
    "    location = []\n",
    "    experience = []\n",
    "    for i in range(10):\n",
    "        title.append(titles_tags[i].text)\n",
    "        location.append(location_tags[i].text)\n",
    "        company.append(company_tags[i].text)\n",
    "        experience.append(experience_tags[i].text)\n",
    "        \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(job_title=title,\n",
    "                  location=location,\n",
    "                  company_name=company,\n",
    "                  experience=experience)\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_top_10_naukri_jobs('Data Analyst','Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - SAP</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "      <td>Boston Scientific Corporation</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Security Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst -Azure Data lake, Azure Data factory</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business / Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Outsource Big Data</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...   \n",
       "1                                 Data Analyst - SAP   \n",
       "2                   Hiring Data Analysts on Contract   \n",
       "3                                Senior Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                              Security Data Analyst   \n",
       "6  Data Analyst -Azure Data lake, Azure Data factory   \n",
       "7                            Business / Data Analyst   \n",
       "8                     Data Analyst - O2C - Bangalore   \n",
       "9                                Intern Data Analyst   \n",
       "\n",
       "                              location                         company_name  \\\n",
       "0                            Bengaluru    Flipkart Internet Private Limited   \n",
       "1      Pune, Delhi, Bengaluru, Gurgaon        Boston Scientific Corporation   \n",
       "2                            Bengaluru    Flipkart Internet Private Limited   \n",
       "3                Bengaluru / Bangalore                   Schneider Electric   \n",
       "4                            Bengaluru  Shell India Markets Private Limited   \n",
       "5                            Bengaluru                Philips India Limited   \n",
       "6  Chennai, Pune, Bengaluru, Hyderabad                     Mindtree Limited   \n",
       "7                            Bengaluru               IBM India Pvt. Limited   \n",
       "8                            Bengaluru               RANDSTAD INDIA PVT LTD   \n",
       "9                            Bengaluru                   Outsource Big Data   \n",
       "\n",
       "  experience  \n",
       "0    1-4 Yrs  \n",
       "1    3-5 Yrs  \n",
       "2    2-5 Yrs  \n",
       "3    2-5 Yrs  \n",
       "4    5-8 Yrs  \n",
       "5    2-4 Yrs  \n",
       "6    5-9 Yrs  \n",
       "7    2-4 Yrs  \n",
       "8    2-4 Yrs  \n",
       "9    0-1 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) To scrape data for “Data Scientist” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_10_naukri_job_description(job=None,loc=None):\n",
    "    \n",
    "    ### Get naukri webpage\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_location = driver.find_element_by_id('qsb-location-sugg')\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button[@class='btn']\")\n",
    "    \n",
    "    ### Enter the required desgination/location and click search \n",
    "    if job != None:\n",
    "        search_job.send_keys(job)\n",
    "    if loc != None:\n",
    "        search_location.send_keys(loc)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Find tags containing the job details\n",
    "    titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    \n",
    "    ### scrape the data for the first 10 jobs results\n",
    "    title = []\n",
    "    company = []\n",
    "    location = []\n",
    "    jd_link = []\n",
    "    jd_desc = []\n",
    "    for i in range(10):\n",
    "        title.append(titles_tags[i].text)\n",
    "        location.append(location_tags[i].text)\n",
    "        company.append(company_tags[i].text)\n",
    "        ### Get the link of the job description\n",
    "        jd_link.append(titles_tags[i].get_attribute(\"href\"))\n",
    "        \n",
    "    ### Scrape job descriptions\n",
    "    for i in jd_link:\n",
    "        driver.get(str(i))\n",
    "        try:\n",
    "            jd_desc.append(driver.find_element_by_xpath(\"//section[@class='job-desc']\").text)\n",
    "        except NoSuchElementException:\n",
    "            jd_desc.append('None')\n",
    "            \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(job_title=title,\n",
    "                  location=location,\n",
    "                  company_name=company,\n",
    "                  job_description=jd_desc)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_top_10_naukri_job_description('Data Scientist','Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Job description\\nData Scientist - Data Mining/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Job description\\nWorking experience in Artific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Job description\\n\\nWe are hiring Data Scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Analyst-Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Job description\\nRole Description:\\nA Sr. Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "1  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "2    Data Scientist - Machine Learning (Commerce BU)   \n",
       "3                                     Data Scientist   \n",
       "4     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "5     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "6             Senior Data Scientist - NLP/ Python/ R   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8  Data Scientist and Senior Data Scientist Acade...   \n",
       "9                         Sr. Analyst-Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "4                                    Pune, Bengaluru   \n",
       "5                                    Pune, Bengaluru   \n",
       "6                               Bengaluru, Hyderabad   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "8                                          Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                        company_name  \\\n",
       "0       Wrackle Technologies Pvt Ltd   \n",
       "1       Wrackle Technologies Pvt Ltd   \n",
       "2  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "3        Atos Syntel Private Limited   \n",
       "4                 Tech Mahindra Ltd.   \n",
       "5                 Tech Mahindra Ltd.   \n",
       "6                 AVI Consulting LLP   \n",
       "7                           CES Ltd.   \n",
       "8             RANDSTAD INDIA PVT LTD   \n",
       "9                   Mindtree Limited   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description\\nData Scientist - Data Mining/...  \n",
       "1  Job description\\nRoles and Responsibilities\\nR...  \n",
       "2                                               None  \n",
       "3  Job description\\nWorking experience in Artific...  \n",
       "4                                               None  \n",
       "5                                               None  \n",
       "6  Job description\\nRoles and Responsibilities\\nS...  \n",
       "7  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "8  Job description\\n\\nWe are hiring Data Scientis...  \n",
       "9  Job description\\nRole Description:\\nA Sr. Data...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) To scrape data for \"Data Scientist\" jobs using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_10_naukri_jobs_using_filters(job=None,filters=None):\n",
    "    \n",
    "    ### Get naukri webpage\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button[@class='btn']\")\n",
    "    \n",
    "    ### Enter the required desgination/location and click search \n",
    "    if job != None:\n",
    "        search_job.send_keys(job)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    ### Apply location and price range filters\n",
    "    driver.find_element_by_xpath(\"//span[@title='{}' and contains(text(),'{}')]\".format(filters['loc'],filters['loc'])).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//span[@title='{}' and contains(text(),'{}')]\".format(filters['price'],filters['price'])).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Find tags containing the job details\n",
    "    titles_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    \n",
    "    ### scrape the data for the first 10 jobs results\n",
    "    title = []\n",
    "    company = []\n",
    "    location = []\n",
    "    experience = []\n",
    "    for i in range(10):\n",
    "        title.append(titles_tags[i].text)\n",
    "        location.append(location_tags[i].text)\n",
    "        company.append(company_tags[i].text)\n",
    "        experience.append(experience_tags[i].text)\n",
    "        \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(job_title=title,\n",
    "                  location=location,\n",
    "                  company_name=company,\n",
    "                  experience=experience)\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_top_10_naukri_jobs_using_filters('Data Scientist',{'loc':'Delhi/NCR','price':'3-6 Lakhs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - NLP</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Ciena</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                        Senior Data Scientist - NLP   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4                                     Data Scientist   \n",
       "5  GCP Skilled Analytics Resources (Data engineer...   \n",
       "6           Data Scientist - Python/Machine Learning   \n",
       "7                    Data Scientist Machine Learning   \n",
       "8     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "9  Data Scientist - Commercial Planning and Analysis   \n",
       "\n",
       "                                            location  \\\n",
       "0  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...   \n",
       "1                                   Gurgaon Gurugram   \n",
       "2                                          Delhi NCR   \n",
       "3                          Delhi NCR, Noida, Gurgaon   \n",
       "4                                   Gurgaon Gurugram   \n",
       "5                           Pune, Bengaluru, Gurgaon   \n",
       "6                                              Noida   \n",
       "7                                            Gurgaon   \n",
       "8                                              Noida   \n",
       "9                                 Delhi NCR, Gurgaon   \n",
       "\n",
       "                         company_name experience  \n",
       "0                      Country Veggie    1-3 Yrs  \n",
       "1              IBM India Pvt. Limited    4-8 Yrs  \n",
       "2                   IRIS SOFTWARE Inc    4-9 Yrs  \n",
       "3           GABA Consultancy services    0-0 Yrs  \n",
       "4                               Ciena    5-6 Yrs  \n",
       "5  Aerial Telecom Solutions Pvt. Ltd.    3-8 Yrs  \n",
       "6                               Jubna    5-8 Yrs  \n",
       "7                           Delhivery    1-3 Yrs  \n",
       "8                   tech mahindra ltd   5-10 Yrs  \n",
       "9              Air Asia India Limited    1-6 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) To scrape data for first 10 job results for Data scientist Designation in Noida location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_10_glassdoor_jobs(job=None,loc=None):\n",
    "    \n",
    "    ### Get glassdoor webpage\n",
    "    driver.get('https://www.glassdoor.co.in/index.htm')\n",
    "    driver.find_element_by_xpath(\"//span/a[contains(text(),'Jobs')]\").click()\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    job_field = driver.find_element_by_id('sc.keyword')\n",
    "    loc_field = driver.find_element_by_id('sc.location')\n",
    "    search_button = driver.find_element_by_id('HeroSearchButton')\n",
    "    \n",
    "    ### Enter field values\n",
    "    if job != None:\n",
    "        job_field.send_keys(job)\n",
    "    if loc != None:\n",
    "        loc_field.send_keys(loc)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Find tags containing the job details\n",
    "    company_tags = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")\n",
    "    job_age_tags = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    rating_tags = driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "    \n",
    "    ### scrape the data for the first 10 jobs results\n",
    "    company = []\n",
    "    job_age = []\n",
    "    rating = []\n",
    "    for i in range(10):\n",
    "        company.append(company_tags[i].text)\n",
    "        job_age.append(job_age_tags[i].text)\n",
    "        rating.append(rating_tags[i].text)\n",
    "        \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(company_name=company,\n",
    "                  no_of_days_ago=job_age,\n",
    "                  rating=rating)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_top_10_glassdoor_jobs('Data Scientist','Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>no_of_days_ago</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BlackRock</td>\n",
       "      <td>3d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackRock</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abc consultants</td>\n",
       "      <td>3d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>11d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brickred</td>\n",
       "      <td>22d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Terra Economics &amp; Analytics Lab (TEAL)</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Healtheoz India</td>\n",
       "      <td>3d</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company_name no_of_days_ago rating\n",
       "0                               BlackRock             3d    4.1\n",
       "1                               BlackRock             9d    4.1\n",
       "2                         abc consultants             3d    4.1\n",
       "3                                   Adobe             5d    4.4\n",
       "4                          Biz2Credit Inc            11d    3.7\n",
       "5                                Brickred            22d    3.9\n",
       "6  Terra Economics & Analytics Lab (TEAL)             4d    4.9\n",
       "7                    Gauge Data Solutions             3d    3.1\n",
       "8                         Healtheoz India             3d    4.8\n",
       "9                         Priority Vendor             3d    3.7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) To scrape the salary data for Data Scientist designation in Noida location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_10_glassdoor_salaries(job=None,loc=None):\n",
    "    \n",
    "    ### Get glassdoor webpage\n",
    "    driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    job_field = driver.find_element_by_id('KeywordSearch')\n",
    "    loc_field = driver.find_element_by_id('LocationSearch')\n",
    "    search_button = driver.find_element_by_id('HeroSearchButton')\n",
    "    \n",
    "    ### Enter field values\n",
    "    if job != None:\n",
    "        job_field.clear()\n",
    "        job_field.send_keys(job)\n",
    "    if loc != None:\n",
    "        loc_field.clear()\n",
    "        loc_field.send_keys(loc)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Find tags containing the salaries details\n",
    "    job_info_tags = driver.find_elements_by_xpath(\"//div[@data-test='job-info']\")\n",
    "    avg_salary_tags = driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "    min_max_salary_tags = driver.find_elements_by_xpath(\"//div[contains(@class,'common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container')]\")\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### scrape the data for the first 10 salary results\n",
    "    company = []\n",
    "    salaries = []\n",
    "    avg_salary = []\n",
    "    min_salary = []\n",
    "    max_salary = []\n",
    "    for i in range(10):\n",
    "        info = job_info_tags[i].text.split('\\n')\n",
    "        company.append(info[1])\n",
    "        salaries.append(info[2])\n",
    "        avg_salary.append(avg_salary_tags[i].text)\n",
    "        minmax_salary = min_max_salary_tags[i].text.split('\\n')\n",
    "        min_salary.append(minmax_salary[0])\n",
    "        max_salary.append(minmax_salary[1])\n",
    "    \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(company_name=company,\n",
    "                       no_of_salaries=salaries,\n",
    "                       avg_salary=avg_salary,\n",
    "                       min_salary=min_salary,\n",
    "                       max_salary=max_salary)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_top_10_glassdoor_salaries('Data Scientist','Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>no_of_salaries</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12,64,182</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,630K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹ 7,30,968</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,614K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 5,99,668</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,010K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 9,94,055</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,215K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 7,39,040</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,732K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 13,37,114</td>\n",
       "      <td>₹717K</td>\n",
       "      <td>₹1,575K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 7,80,374</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,152K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,98,792</td>\n",
       "      <td>₹621K</td>\n",
       "      <td>₹1,696K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 10,08,143</td>\n",
       "      <td>₹793K</td>\n",
       "      <td>₹1,264K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 11,34,989</td>\n",
       "      <td>₹576K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_name no_of_salaries   avg_salary min_salary  \\\n",
       "0                       Delhivery    13 salaries  ₹ 12,64,182      ₹450K   \n",
       "1              Ericsson-Worldwide    12 salaries   ₹ 7,30,968      ₹350K   \n",
       "2       Tata Consultancy Services    10 salaries   ₹ 5,99,668      ₹336K   \n",
       "3                       Accenture    10 salaries   ₹ 9,94,055      ₹577K   \n",
       "4                             IBM    10 salaries   ₹ 7,39,040      ₹587K   \n",
       "5              UnitedHealth Group     9 salaries  ₹ 13,37,114      ₹717K   \n",
       "6              Valiance Solutions     8 salaries   ₹ 7,80,374      ₹502K   \n",
       "7                      Innovaccer     7 salaries  ₹ 11,98,792      ₹621K   \n",
       "8  Cognizant Technology Solutions     6 salaries  ₹ 10,08,143      ₹793K   \n",
       "9                     EXL Service     6 salaries  ₹ 11,34,989      ₹576K   \n",
       "\n",
       "  max_salary  \n",
       "0   ₹11,630K  \n",
       "1    ₹1,614K  \n",
       "2    ₹1,010K  \n",
       "3    ₹2,215K  \n",
       "4    ₹2,732K  \n",
       "5    ₹1,575K  \n",
       "6    ₹1,152K  \n",
       "7    ₹1,696K  \n",
       "8    ₹1,264K  \n",
       "9    ₹1,500K  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) To scrape data of first 100 sunglasses listings on flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_100_items_on_flipkart(item=None):\n",
    "    \n",
    "    ### Go to Flipkart webpage\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    \n",
    "    ### Close login popup\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    item_field = driver.find_element_by_class_name('_3704LK')\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    \n",
    "    ### Enter field values\n",
    "    if item != None:\n",
    "        item_field.send_keys(item)\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### scrape top 100 product data\n",
    "    brand = []\n",
    "    product_desc = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    count = 0\n",
    "    limit = 100\n",
    "    while count < limit:\n",
    "        ### Find tags containing the salaries details\n",
    "        product_tags = driver.find_elements_by_xpath(\"//div[@class='_2B099V']\")\n",
    "        for i in product_tags:\n",
    "            if count == limit:\n",
    "                break\n",
    "            brand.append(i.find_element_by_class_name('_2WkVRV').text)\n",
    "            product_desc.append(i.find_element_by_xpath(\"a[contains(@class,'IRpwTa')]\").text)\n",
    "            price.append(i.find_element_by_class_name('_30jeq3').text)\n",
    "            try:\n",
    "                discount.append(i.find_element_by_class_name('_3Ay6Sb').text)\n",
    "            except NoSuchElementException:\n",
    "                discount.append('None')\n",
    "            count = count + 1\n",
    "        if count < limit:\n",
    "            ### Goto next page\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span[contains(text(),'Next')]\").click()\n",
    "                \n",
    "        time.sleep(5)\n",
    "    \n",
    "    ### create dictionary of the data \n",
    "    data_dict = dict(brand=brand,\n",
    "                       product_desc=product_desc,\n",
    "                       price=price,\n",
    "                       discount=discount)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = top_10_items_on_flipkart('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_desc</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (54)</td>\n",
       "      <td>₹197</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer, Wayfarer, Wa...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Deixels</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹374</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹314</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (62)</td>\n",
       "      <td>₹448</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                       product_desc price  \\\n",
       "0   kingsunglasses      UV Protection, Mirrored Round Sunglasses (54)  ₹197   \n",
       "1   kingsunglasses  Mirrored, UV Protection Wayfarer, Wayfarer, Wa...  ₹284   \n",
       "2         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "3         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "4         Fastrack             UV Protection Wayfarer Sunglasses (56)  ₹599   \n",
       "..             ...                                                ...   ...   \n",
       "95         Deixels   UV Protection Rectangular Sunglasses (Free Size)  ₹189   \n",
       "96          Gansta              UV Protection Aviator Sunglasses (57)  ₹374   \n",
       "97       Royal Son            Mirrored Aviator Sunglasses (Free Size)  ₹399   \n",
       "98          PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹314   \n",
       "99          Aislin   Polarized, UV Protection Aviator Sunglasses (62)  ₹448   \n",
       "\n",
       "   discount  \n",
       "0   83% off  \n",
       "1   81% off  \n",
       "2   37% off  \n",
       "3   37% off  \n",
       "4   33% off  \n",
       "..      ...  \n",
       "95  87% off  \n",
       "96  81% off  \n",
       "97  73% off  \n",
       "98  80% off  \n",
       "99  79% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) To scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews_from_flipkart():\n",
    "    \n",
    "    ### Go to Flipkart review page\n",
    "    driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "    driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### scrape top 100 reviews\n",
    "    rating = []\n",
    "    review_summary = []\n",
    "    full_review = []\n",
    "    count = 0\n",
    "    limit = 100\n",
    "    while count < limit:\n",
    "        ### Find tags containing the reviews\n",
    "        review_tags = driver.find_elements_by_xpath(\"//div[@class='_1AtVbE col-12-12']/div[@class='_27M-vq']\")\n",
    "        for i in review_tags:\n",
    "            if count == limit:\n",
    "                break\n",
    "            rating.append(i.find_element_by_class_name('_3LWZlK').text)\n",
    "            review_summary.append(i.find_element_by_class_name('_2-N8zT').text)\n",
    "            full_review.append(i.find_element_by_class_name('t-ZTKy').text)\n",
    "            count = count + 1\n",
    "        if count < limit:\n",
    "             ### Goto next page\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span[contains(text(),'Next')]\").click()\n",
    "            \n",
    "        time.sleep(2)\n",
    "    \n",
    "    ### create dictionary of the data\n",
    "    data_dict = dict(rating=rating,\n",
    "                       review_summary=review_summary,\n",
    "                       full_review=full_review)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_reviews_from_flipkart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Everything good as expected from Apple, but on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>The only issue is the unavailability of fast c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>Great product as usual. Handy phone with best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>It’s being awesome to buy an apple product sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>excellent mobile phone with amazing feautures....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      review_summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5  Highly recommended   \n",
       "3       5    Perfect product!   \n",
       "4       5           Brilliant   \n",
       "..    ...                 ...   \n",
       "95      5              Super!   \n",
       "96      5              Super!   \n",
       "97      4         Good choice   \n",
       "98      5   Terrific purchase   \n",
       "99      5      Simply awesome   \n",
       "\n",
       "                                          full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  Everything good as expected from Apple, but on...  \n",
       "96  The only issue is the unavailability of fast c...  \n",
       "97  Great product as usual. Handy phone with best ...  \n",
       "98  It’s being awesome to buy an apple product sim...  \n",
       "99  excellent mobile phone with amazing feautures....  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) To scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the same function from the above problem i.e top_100_items_on_flipkart\n",
    "data = top_100_items_on_flipkart('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_desc</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edoeviv</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELISEO</td>\n",
       "      <td>Hype-21 Sneakers For Men</td>\n",
       "      <td>₹556</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Chevit Trendy Fashion Sports Combo Pack of 3 P...</td>\n",
       "      <td>₹597</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Men-9097 Latest Collection of Stylish Casual C...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>EVAW2 Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MOU</td>\n",
       "      <td>Zar Check Sneakers Sneakers For Men</td>\n",
       "      <td>₹523</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DOC Martin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brand                                       product_desc  \\\n",
       "0               Edoeviv                                   Sneakers For Men   \n",
       "1                ELISEO                           Hype-21 Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3   World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "4          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95               Chevit  Chevit Trendy Fashion Sports Combo Pack of 3 P...   \n",
       "96  World Wear Footwear  Men-9097 Latest Collection of Stylish Casual C...   \n",
       "97     Absolute comfort                             EVAW2 Sneakers For Men   \n",
       "98                  MOU                Zar Check Sneakers Sneakers For Men   \n",
       "99           DOC Martin                                   Sneakers For Men   \n",
       "\n",
       "   price discount  \n",
       "0   ₹499  37% off  \n",
       "1   ₹556  44% off  \n",
       "2   ₹449  77% off  \n",
       "3   ₹474  76% off  \n",
       "4   ₹379  62% off  \n",
       "..   ...      ...  \n",
       "95  ₹597  66% off  \n",
       "96  ₹299  70% off  \n",
       "97  ₹199  60% off  \n",
       "98  ₹523  47% off  \n",
       "99  ₹999  68% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) To scrape first 100 shoes data from Myntra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Note : The price range Rs. 6649 to Rs. 13099 was not found in the filter chekboxes, so to set an example I've used another one among the available price range filters i.e Rs. 5357 to Rs. 10505**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_myntra_shoes_products():\n",
    "    \n",
    "    ### Goto myntra shoes page\n",
    "    driver.get('https://www.myntra.com/shoes')\n",
    "    \n",
    "    ### Apply filters\n",
    "    driver.find_element_by_xpath(\"//span[@data-colorhex='black' and @class='colour-label colour-colorDisplay']\").click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//input[@class='price-input' and @value='5357.0 TO 10505.0']/following-sibling::div\").click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### scrape top 100 product data\n",
    "    brand = []\n",
    "    product_desc = []\n",
    "    price = []\n",
    "    count = 0\n",
    "    limit = 100\n",
    "    while count < limit:\n",
    "        ### Find tags containing the reviews\n",
    "        product_tags = driver.find_elements_by_class_name('product-base')\n",
    "        for i in product_tags:\n",
    "            if count == limit:\n",
    "                break\n",
    "            brand.append(i.find_element_by_class_name('product-brand').text)\n",
    "            product_desc.append(i.find_element_by_class_name('product-product').text)\n",
    "            try:\n",
    "                price.append(i.find_element_by_class_name('product-discountedPrice').text)\n",
    "            except NoSuchElementException:\n",
    "                price.append(i.find_element_by_class_name('product-price').text)\n",
    "            count = count + 1\n",
    "        if count < limit:\n",
    "            ### Goto next page\n",
    "            driver.find_element_by_class_name('pagination-next').click()\n",
    "\n",
    "        time.sleep(5)\n",
    "    \n",
    "    ### create dictionary of the data\n",
    "    data_dict = dict(brand=brand,\n",
    "                       product_desc=product_desc,\n",
    "                       price=price)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_myntra_shoes_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_desc</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men A.R. TRAINER Sneakers</td>\n",
       "      <td>Rs. 5359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Formal Leather Brogues</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>Rs. 6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Oxfords</td>\n",
       "      <td>Rs. 9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Loafers</td>\n",
       "      <td>Rs. 6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Formal Genuine Leather Derbys</td>\n",
       "      <td>Rs. 6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Women Flexagon Training Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                             product_desc     price\n",
       "0       ADIDAS Originals                Men A.R. TRAINER Sneakers  Rs. 5359\n",
       "1              Cole Haan               Men Formal Leather Brogues  Rs. 9999\n",
       "2                   Puma           Men HYBRID NETFIT Running Shoe  Rs. 6599\n",
       "3           Kenneth Cole         Men Solid Leather Formal Oxfords  Rs. 9513\n",
       "4              Cole Haan              Women Woven Design Sneakers  Rs. 7499\n",
       "..                   ...                                      ...       ...\n",
       "95          Kenneth Cole          Men Solid Leather Formal Derbys  Rs. 6293\n",
       "96          Kenneth Cole         Men Solid Leather Formal Loafers  Rs. 6153\n",
       "97          Kenneth Cole  Men Solid Formal Genuine Leather Derbys  Rs. 6153\n",
       "98                Reebok            Women Flexagon Training Shoes  Rs. 7999\n",
       "99  Heel & Buckle London                      Women Leather Pumps  Rs. 7192\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) To scrape amazon product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_amazon_product_data(limit=10):\n",
    "    \n",
    "    ### Goto amazon webpage\n",
    "    driver.get('https://www.amazon.in/')\n",
    "    \n",
    "    ### Find elements in the search field\n",
    "    item_field = driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_button = driver.find_element_by_id('nav-search-submit-button')\n",
    "    \n",
    "    ### Enter field values\n",
    "    item_field.send_keys('Laptop')\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### Apply filters\n",
    "    driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i7']//label\").click()\n",
    "    driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i9']//label\").click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    ### scrape top 10 product data\n",
    "    product = []\n",
    "    rating = []\n",
    "    price = []\n",
    "    count = 0\n",
    "    while count < limit:\n",
    "        ### Find tags containing the reviews\n",
    "        product_tags = driver.find_elements_by_xpath(\n",
    "            \"\"\"//div[@class='s-result-item s-asin sg-col-0-of-12 sg-col-16-of-20 sg-col sg-col-12-of-16' \n",
    "            or @class='s-result-item s-asin sg-col-0-of-12 sg-col-16-of-20 AdHolder sg-col sg-col-12-of-16']\"\"\")\n",
    "        for i in range(len(product_tags)):\n",
    "            if count == limit:\n",
    "                break\n",
    "            product.append(product_tags[i].find_element_by_class_name('a-text-normal').text)\n",
    "            try:\n",
    "                price.append(product_tags[i].find_element_by_class_name('a-price-whole').text)\n",
    "            except NoSuchElementException:\n",
    "                price.append('None')\n",
    "            try:\n",
    "                rating.append(str(product_tags[i].find_element_by_class_name('a-icon-alt').get_attribute('innerHTML')))\n",
    "            except NoSuchElementException:\n",
    "                rating.append('None')\n",
    "            count = count + 1\n",
    "        if count < limit:\n",
    "            ### Goto next page\n",
    "            driver.find_element_by_xpath(\"//li[@class='a-last']/a\").click()\n",
    "            \n",
    "        time.sleep(10)\n",
    "    \n",
    "    ### create dictionary of the data\n",
    "    data_dict = dict(product=product,\n",
    "                       rating=rating,\n",
    "                       price=price)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scrape_amazon_product_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>50,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>2.4 out of 5 stars</td>\n",
       "      <td>1,97,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>50,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>87,029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>74,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>1,10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>75,493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>95,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product              rating  \\\n",
       "0  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.2 out of 5 stars   \n",
       "1  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  2.4 out of 5 stars   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.2 out of 5 stars   \n",
       "3  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...  3.8 out of 5 stars   \n",
       "4  MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...  4.2 out of 5 stars   \n",
       "5  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...  3.5 out of 5 stars   \n",
       "6  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...  3.3 out of 5 stars   \n",
       "7  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.0 out of 5 stars   \n",
       "8  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...  4.3 out of 5 stars   \n",
       "9  (Renewed) Dell Latitude E6420 14 Inch Laptop (...  1.0 out of 5 stars   \n",
       "\n",
       "      price  \n",
       "0    50,999  \n",
       "1  1,97,200  \n",
       "2    50,999  \n",
       "3    87,029  \n",
       "4      None  \n",
       "5    74,490  \n",
       "6  1,10,000  \n",
       "7    75,493  \n",
       "8    95,290  \n",
       "9      None  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
